{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 텐서\n",
    "---\n",
    "   \n",
    "파이토치의 텐서는 넘파이의 배열은 ndarray와 같은 개념이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([[1, 2], [3, 4]]))\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2 Autograd\n",
    "---\n",
    "자동으로 미분 및 역전파를 수행하는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.1767e+04,  4.5783e-41],\n",
       "        [-9.1767e+04,  1.1363e+12]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(2, 2)\n",
    "y = torch.FloatTensor(2, 2)\n",
    "y.requires_grad_(True)\n",
    "\n",
    "z = (x + y) + torch.FloatTensor(2, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기가 필요가 없는 연산의 경우 다음과 같이 with 문법을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0750e+05,  9.1566e-41],\n",
       "        [-2.4030e-02,  4.5783e-41]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(2, 2)\n",
    "y = torch.FloatTensor(2, 2)\n",
    "y.requires_grad_(True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = (x + y) + torch.FloatTensor(2, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.3 피드포워드\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.6851e-15,  0.0000e+00,  4.2237e-34,  0.0000e+00, -6.7247e-39],\n",
       "        [ 8.9683e-44,  0.0000e+00,  2.0179e-43,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.4165e+10, -5.6062e-36, -8.9201e+07,  3.0600e+21,  1.4202e+03],\n",
       "        [       -inf,  0.0000e+00,  2.0179e-43,  0.0000e+00, -5.3671e+13],\n",
       "        [-7.6375e+07,  3.0228e-38,  4.8318e+05,  2.0309e-11, -7.6577e+00],\n",
       "        [ 8.4216e+09, -4.2014e-36,  8.4216e+09,  2.0309e-11, -7.5024e-34],\n",
       "        [ 3.3500e-14,  0.0000e+00,  2.0179e-43,  0.0000e+00,  1.8630e-07],\n",
       "        [ 8.9683e-44,  0.0000e+00,  2.0179e-43,  0.0000e+00,  0.0000e+00],\n",
       "        [-9.6094e-21,  0.0000e+00, -9.6094e-21,  3.0600e+21, -8.5095e-20],\n",
       "        [       -inf,  0.0000e+00,  4.2038e-34,  0.0000e+00, -5.3671e+13],\n",
       "        [ 8.9683e-44,  0.0000e+00,  2.0179e-43,  0.0000e+00,  0.0000e+00],\n",
       "        [-9.4571e-34,  0.0000e+00,  5.9545e-36,  0.0000e+00, -9.4819e-41],\n",
       "        [-3.6408e+18,  0.0000e+00,  4.1938e-34,  0.0000e+00,         inf],\n",
       "        [ 8.9683e-44,  0.0000e+00,  2.0179e-43,  0.0000e+00,  0.0000e+00],\n",
       "        [-9.6094e-21,  0.0000e+00, -9.6094e-21,  3.0600e+21, -8.5095e-20],\n",
       "        [        inf,  0.0000e+00, -8.2495e-15,  0.0000e+00,        -inf]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def linear(x, W, b):\n",
    "    y = torch.mm(x, W) + b\n",
    "    \n",
    "    return y\n",
    "\n",
    "x = torch.FloatTensor(16, 10)\n",
    "W = torch.FloatTensor(10, 5)\n",
    "b = torch.FloatTensor(5)\n",
    "\n",
    "y = linear(x, W, b)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.4 nn.Module\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28, -2.9634e-36,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28, -2.5706e-40,  1.2432e-15, -1.7108e-22],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28, -2.9634e-36,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28, -3.8565e-40,  6.2160e-16, -3.4216e-22],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28, -3.3255e-36,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7497e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37],\n",
       "        [ 6.7331e+22,  7.1221e+28,  1.3593e-43,  0.0000e+00,  5.7474e-37]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter라는 클래스를 이용하여 텐서를 감싸야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyLinear, self).__init__()\n",
    "        \n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_size, output_size), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size), requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  9.6185e-40,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41, -4.4513e-34],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5796e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  9.6185e-40,  0.0000e+00],\n",
       "        [-6.0559e+07, -1.6271e-17, -6.0560e+07,  3.0260e-38, -6.3874e-41],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  8.9160e+03],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41, -6.3874e-41],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41,  0.0000e+00],\n",
       "        [ 2.3017e+03, -1.6271e-17,  9.9170e+02,  4.5783e-41, -8.6658e-35]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10, 5]), torch.Size([5])]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyLinear, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5367e+35, -1.8799e+36,  1.3357e+36, -5.3694e+35, -2.6704e+36],\n",
       "        [-1.0570e+30,  1.2964e+30, -1.1045e+30,  1.5936e+30,  2.4191e+29],\n",
       "        [ 2.9592e-02, -2.2418e-01, -2.9826e-01, -1.6531e-01, -6.4113e-02],\n",
       "        [ 2.9592e-02, -2.2418e-01, -2.9826e-01, -1.6531e-01, -6.4113e-02],\n",
       "        [-1.8470e+04, -1.7492e+04,  2.2527e+04, -2.5164e+03, -2.3268e+04],\n",
       "        [-8.5030e+03, -1.0031e+04, -1.1707e+04,  1.0336e+04, -8.1551e+02],\n",
       "        [ 2.9592e-02, -2.2418e-01, -2.9826e-01, -1.6531e-01, -6.4113e-02],\n",
       "        [ 2.5689e+04,  2.8869e+04,  3.4992e+04, -3.1496e+04,  2.2031e+03],\n",
       "        [ 2.9592e-02, -2.2418e-01, -2.9826e-01, -1.6531e-01, -6.4113e-02],\n",
       "        [ 2.7176e+22, -1.5367e+22,  3.6064e+21,  3.2541e+22,  2.9059e+22],\n",
       "        [-1.8470e+04, -1.7492e+04,  2.2527e+04, -2.5164e+03, -2.3268e+04],\n",
       "        [ 2.8047e-02, -2.1623e-01, -3.0699e-01, -1.7144e-01, -5.9470e-02],\n",
       "        [-3.8829e+29,  1.6013e+29,  4.4906e+27,  2.8601e+29,  3.0906e+29],\n",
       "        [ 7.6159e+21, -9.3405e+21,  7.9577e+21, -1.1482e+22, -1.7429e+21],\n",
       "        [ 2.9592e-02, -2.2418e-01, -2.9826e-01, -1.6531e-01, -6.4113e-02],\n",
       "        [ 2.7176e+22, -1.5367e+22,  3.6064e+21,  3.2541e+22,  2.9059e+22]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([5, 10]), torch.Size([5])]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLinear(\n",
      "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.5 역전파 수행\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 100\n",
    "\n",
    "x = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)\n",
    "loss = (objective - y.sum())**2\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.6 train()과 eval()\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLinear(\n",
       "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training...\n",
    "linear.eval()\n",
    "# Do some inference process.\n",
    "linear.train()\n",
    "# Restart training, again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.7 선형회기분석 예제\n",
    "--\n",
    "\n",
    "1. 임의로 생성한 텐서들을\n",
    "2. 근사하고자 하는 정답 함수에 넣어 정답(y)를 구하고\n",
    "3. 그 정답과 신경망을 통과한 yhat과의 차이를 MSE를 통해 구하여\n",
    "4. 확률적 경사하강법(SGD)를 통해 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth(x):\n",
    "    return 3 * x[:, 0] + x[:, 1] - 2 * x[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, optim):\n",
    "    # initialize gradients in all parameters in module\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # feed-forward\n",
    "    y_hat = model(x)\n",
    "    # get error between answer and inferenced\n",
    "    loss = ((y - y_hat)**2).sum() / x.size(0)\n",
    "    \n",
    "    # back-porpagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # one-step of gradient descent\n",
    "    optim.step()\n",
    "    \n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "n_epochs = 1000\n",
    "n_iter = 10000\n",
    "\n",
    "model = MyModel(3, 1)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8132) tensor(0.9000) tensor(0.7712)\n",
      "tensor(0.4977) tensor(0.9000) tensor(0.8012)\n",
      "tensor(0.3485) tensor(0.9000) tensor(0.8357)\n",
      "tensor(0.2378) tensor(0.9000) tensor(0.8804)\n",
      "tensor(0.1672) tensor(0.9000) tensor(0.8914)\n",
      "tensor(0.1133) tensor(0.9000) tensor(0.9013)\n",
      "tensor(0.0779) tensor(0.9000) tensor(0.9108)\n",
      "tensor(0.0547) tensor(0.9000) tensor(0.9201)\n",
      "tensor(0.0383) tensor(0.9000) tensor(0.9220)\n",
      "tensor(0.0271) tensor(0.9000) tensor(0.9228)\n",
      "tensor(0.0194) tensor(0.9000) tensor(0.9263)\n",
      "tensor(0.0136) tensor(0.9000) tensor(0.9308)\n",
      "tensor(0.0097) tensor(0.9000) tensor(0.9304)\n",
      "tensor(0.0068) tensor(0.9000) tensor(0.9310)\n",
      "tensor(0.0049) tensor(0.9000) tensor(0.9291)\n",
      "tensor(0.0035) tensor(0.9000) tensor(0.9280)\n",
      "tensor(0.0025) tensor(0.9000) tensor(0.9265)\n",
      "tensor(0.0018) tensor(0.9000) tensor(0.9256)\n",
      "tensor(0.0013) tensor(0.9000) tensor(0.9245)\n",
      "tensor(0.0009) tensor(0.9000) tensor(0.9228)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        x = torch.rand(batch_size, 3)\n",
    "        y = ground_truth(x.data)\n",
    "        \n",
    "        loss = train(model, x, y, optim)\n",
    "        \n",
    "        avg_loss += loss\n",
    "    avg_loss = avg_loss / n_iter\n",
    "        \n",
    "    # simple test sample to check the network\n",
    "    x_valid = torch.FloatTensor([[.3, .2, .1]])\n",
    "    y_valid = ground_truth(x_valid.data)\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "    \n",
    "    print(avg_loss, y_valid.data[0], y_hat.data[0, 0])\n",
    "    \n",
    "    if avg_loss < .001: # finish if the training if the loss is smaller than .001\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.8 GPU 사용하기\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that tensor is declared in torch.cuda.\n",
    "x = torch.cuda.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "# .cuda() let module move to GPU memory\n",
    "linear.cuda()\n",
    "y = linear(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
